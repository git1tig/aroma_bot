# -*- coding: utf-8 -*- a change
import os
import telebot
import openai
from dotenv import load_dotenv
import pandas as pd
import requests
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import MarkdownHeaderTextSplitter
import re

# === –ó–ê–ì–†–£–ó–ö–ê API-–ö–õ–Æ–ß–ï–ô ===
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_BOT_TOKEN or not OPENAI_API_KEY:
    raise ValueError("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç TELEGRAM_BOT_TOKEN –∏–ª–∏ OPENAI_API_KEY –≤ .env —Ñ–∞–π–ª–µ!")

openai.api_key = OPENAI_API_KEY
bot = telebot.TeleBot(TELEGRAM_BOT_TOKEN)

# === –ü–£–¢–ò –ö –§–ê–ô–õ–ê–ú ===
MASLA_FILE = "/app/mono_oils.txt"  # –§–∞–π–ª —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –º–∞—Å–µ–ª
FAISS_INDEX_FILE = "/app/index.faiss"  # –§–∞–π–ª —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ FAISS

# === –ü–†–û–í–ï–†–ö–ê –ò –ó–ê–ì–†–£–ó–ö–ê FAISS ===
embs = OpenAIEmbeddings()

if os.path.exists(FAISS_INDEX_FILE):
    print(" –ó–∞–≥—Ä—É–∂–∞–µ–º FAISS-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏–∑ —Ñ–∞–π–ª–∞...")
    db = FAISS.load_local(FAISS_INDEX_FILE, embs, allow_dangerous_deserialization=True)
else:
    print("–§–∞–π–ª FAISS-—Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –∑–∞–Ω–æ–≤–æ...")

    if not os.path.exists(MASLA_FILE):
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å: {MASLA_FILE}")

        raise FileNotFoundError(f"‚ùå –§–∞–π–ª {MASLA_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω! –î–æ–±–∞–≤—å –µ–≥–æ –≤ –∫–∞—Ç–∞–ª–æ–≥.")

    with open(MASLA_FILE, 'r', encoding='utf-8') as f:
        my_text = f.read()

    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏
    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[("#", "Header 1")])
    chunks = splitter.split_text(my_text)

    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    db = FAISS.from_documents(chunks, embs)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    db.save_local(FAISS_INDEX_FILE)
    print("‚úÖ FAISS-—Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ–∑–¥–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")

# === –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò–ó GOOGLE SHEETS (UTF-8) ===
SHEET_URL = "https://docs.google.com/spreadsheets/d/1MknmvI9_YvjM7bge9tPryRKrrzCi-Ywc5ZfYiyb6Bdg/export?format=csv"
COLUMN_NAMES = ["Name", "Vol", "Price"]

try:
    df = pd.read_csv(SHEET_URL, names=COLUMN_NAMES, encoding='utf-8')
    print("‚úÖ –î–∞–Ω–Ω—ã–µ –æ –º–∞—Å–ª–∞—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
except Exception as e:
    print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö:", e)
    df = pd.DataFrame(columns=COLUMN_NAMES)  # –ü—É—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞, –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å

# === GPT-–§–£–ù–ö–¶–ò–ò ===
s1 = "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –º–∞—Å–µ–ª..."
s2 = "–û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–æ–µ –º–∞—Å–ª–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞..."

def gpt_for_query(prompt, system):
    response = openai.chat.completions.create(
        model='gpt-4o-mini',
        messages=[{"role": "system", "content": system},
                  {"role": "user", "content": prompt}],
        temperature=1
    )
    return response.choices[0].message.content

# === –¢–ï–õ–ï–ì–†–ê–ú-–ë–û–¢ ===
user_states = {}
drops_counts = {}
current_oils = {}
task_is_over = {}
drop_session_changes = {}

WAITING_OIL_NAME = "waiting_for_oil"
WAITING_DROPS = 'waiting_for_drop_quantity'
WAITING_NEXT_OIL = 'waiting_for_next_oil'
DROP_STOP = 'drop_stop'

@bot.message_handler(commands=['—Ä'])
def oil_command(message):
    bot.reply_to(message, "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Å–ª–∞ ('*' - –∑–∞–∫–æ–Ω—á–∏—Ç—å –≤–≤–æ–¥):")
    user_states[message.chat.id] = WAITING_NEXT_OIL

@bot.message_handler(commands=['–º'])
def oil_command(message):
    bot.reply_to(message, "–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Å–ª–∞:")
    user_states[message.chat.id] = WAITING_OIL_NAME

@bot.message_handler(commands=['—Å—Ç–æ–ø'])
def cancel_command(message):
    bot.reply_to(message, "–ö–æ–º–∞–Ω–¥–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ —Å /–º.")
    user_states.pop(message.chat.id, None)

@bot.message_handler(func=lambda message: True)
def handle_input(message):
    user_input = message.text.strip().lower()
    
    if message.chat.id in user_states:
        if user_states[message.chat.id] == WAITING_OIL_NAME:
            docs = db.similarity_search_with_score(user_input, k=1)
            if docs[0][1] < 0.37:
                bot.reply_to(message, f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ {user_input}: {docs[0][0].page_content}")
            else:
                docs = db.similarity_search(gpt_for_query(user_input, s2), k=1)
                bot.reply_to(message, f'–ü–æ–¥ –≤–∞—à –∑–∞–ø—Ä–æ—Å {user_input} –ø–æ–¥—Ö–æ–¥–∏—Ç —ç—Ç–æ: {docs[0].page_content}')

    else:
        gpt_generated = gpt_for_query(message.text, s1)
        docs = db.similarity_search(gpt_generated, k=5)
        response_text = "\n".join([doc.page_content for doc in docs])
        bot.reply_to(message, response_text)

if __name__ == "__main__":
    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è...")
    bot.infinity_polling()
